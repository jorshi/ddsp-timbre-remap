{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from timbreremap.np import OnsetFrames\n",
    "from timbreremap.data import OnsetFeatureDataModule\n",
    "import timbreremap.feature as feature\n",
    "from timbreremap.synth import Snare808\n",
    "from timbreremap.loss import FeatureDifferenceLoss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 48000\n",
    "data_path = \"audio/carson_gant_drums/performance.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drums, sr = torchaudio.load(data_path)\n",
    "drums = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sample_rate)(drums)[:1]\n",
    "print(drums.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(drums.squeeze().numpy(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_detection = OnsetFrames(sr, 256)\n",
    "onset_times = onset_detection.onset(drums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(drums[0].numpy())\n",
    "\n",
    "# Plot the detected onsets as vlines\n",
    "for onset in onset_times:\n",
    "    plt.vlines(onset, -0.5, 0.5, color=\"red\", alpha=0.5)\n",
    "\n",
    "plt.title(\"Detected Onsets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loudness_extractor(scaling_function: None):\n",
    "    loudness_extractor = feature.Loudness(sample_rate=sample_rate, scaling_function=scaling_function)\n",
    "    frame_extractor = feature.CascadingFrameExtactor(\n",
    "        [loudness_extractor],\n",
    "        [\n",
    "            2,\n",
    "        ],\n",
    "        2048,\n",
    "        512,\n",
    "    )\n",
    "    return frame_extractor\n",
    "\n",
    "onset_frames = OnsetFrames(\n",
    "    sample_rate,\n",
    "    frame_size=sample_rate,\n",
    "    on_thresh=16.0,\n",
    "    wait=1323,\n",
    "    backtrack=16,\n",
    "    overlap_buffer=512,\n",
    ")\n",
    "\n",
    "frames = onset_frames(drums)\n",
    "frames = torch.from_numpy(frames).float()\n",
    "frame_extractor = get_loudness_extractor(None)\n",
    "loudness = frame_extractor(frames)\n",
    "print(loudness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loudness.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = Snare808(\n",
    "    sample_rate=sample_rate,\n",
    "    num_samples=sample_rate,\n",
    "    buffer_noise=True,\n",
    "    buffer_size=sample_rate,\n",
    ")\n",
    "\n",
    "preset = \"808_snare_1.json\"  # @param [\"808_snare_1.json\", \"808_snare_2.json\", \"808_snare_3.json\", \"808_noisy_snare.json\", \"808_open_snare.json\"]\n",
    "preset = f\"../cfg/presets/{preset}\"\n",
    "\n",
    "parameters, _ = synth.load_params_json(preset)\n",
    "audio = synth(parameters)\n",
    "ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gain(extractor, target_audio, audio, ref:int = 0, iters:int = 500):\n",
    "    gain = torch.ones_like(loudness)\n",
    "\n",
    "    # Compute target loudness difference\n",
    "    y = extractor(target_audio)\n",
    "    y_diff = y - y[ref]\n",
    "\n",
    "    y_hat = extractor(audio * gain)\n",
    "    synth_feat = y_hat[0]\n",
    "\n",
    "    assert y.shape == y_hat.shape\n",
    "\n",
    "    gain = torch.nn.Parameter(gain)\n",
    "    optimizer = torch.optim.Adam([gain], lr=1e-2)\n",
    "    loss = FeatureDifferenceLoss()\n",
    "\n",
    "    for i in range(iters):\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = extractor(audio * gain)\n",
    "\n",
    "        err = loss(y_hat, synth_feat, y_diff)\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Step {i}, Loss {err.item()}\")\n",
    "    \n",
    "    return gain.detach(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resynthesize(synth_audio, original_audio, timings):\n",
    "\n",
    "    resynth = torch.zeros_like(original_audio)\n",
    "    for i, onset in enumerate(timings):\n",
    "        start = onset\n",
    "        end = min(onset + synth_audio[i].shape[-1], resynth.shape[-1])\n",
    "        resynth[0, start:end] += synth_audio[i][: end - start]\n",
    "    \n",
    "    return resynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_function = lambda x: -1.0 * torch.pow(x + 0.000001, -0.1)\n",
    "#scaling_function = lambda x: -6.92 + 10.0*torch.log10(x + 1e-8)\n",
    "#scaling_function = None\n",
    "frame_extractor = get_loudness_extractor(scaling_function)\n",
    "\n",
    "gain, y = optimize_gain(frame_extractor, frames, audio, iters=1000)\n",
    "\n",
    "audio_hat = audio * gain.detach().numpy()\n",
    "y_hat = frame_extractor(audio_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y.numpy(), label=\"Original\")\n",
    "plt.plot(y_hat.numpy(), label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "resynth = resynthesize(audio_hat, drums, onset_times)\n",
    "\n",
    "ipd.display(ipd.Audio(drums.squeeze().numpy(), rate=sample_rate))\n",
    "ipd.display(ipd.Audio(resynth.squeeze().numpy(), rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0.001, 0.1, 100)\n",
    "scaling_function = lambda x: -1 * torch.pow(x + 0.0000001, -0.1)\n",
    "scaling_function_2 = lambda x: -1 * torch.pow(x + 0.0000001, -0.1)\n",
    "scaling_function_db = lambda x: -6.92 + 10.0*torch.log10(x + 1e-8)\n",
    "\n",
    "\n",
    "plt.plot(x, scaling_function(x), color=\"red\")\n",
    "# plt.plot(x, scaling_function(x + 0.01))\n",
    "# plt.plot(x, scaling_function(x + 0.02))\n",
    "plt.plot(x, scaling_function(x + 0.05), color=\"red\")\n",
    "\n",
    "# plt.plot(x, scaling_function_db(x), color=\"blue\")\n",
    "# # plt.plot(x, scaling_function_db(x + 0.01))\n",
    "# # plt.plot(x, scaling_function_db(x + 0.02))\n",
    "# plt.plot(x, scaling_function_db(x + 0.05), color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
